{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i7I7O1kv0S21"
      },
      "outputs": [],
      "source": [
        "# Feel free to import any other libraries and modules.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeXRppkryQBV"
      },
      "source": [
        "# Part One: Optimization Algorithms\n",
        "## 1. Gradient Descent\n",
        "The Gradient Descent (GD) algorithm finds the minimum of a given\n",
        "function by taking small steps along the function's gradient:\n",
        "\n",
        ">$\\Theta \\leftarrow \\Theta_0$\n",
        "\n",
        ">**while** stop condition not met **do**\n",
        "\n",
        ">$~~~~$$\\Theta \\leftarrow \\Theta - \\alpha \\nabla_\\Theta f(\\Theta)$\n",
        "\n",
        ">**end while**\n",
        "\n",
        "where $f$ is the function to minimize, $\\nabla_\\Theta f(\\Theta)$\n",
        "denotes $f$'s gradient at $\\Theta$ and $\\alpha$ is the learning rate.\n",
        "\n",
        "**Task1:** Implement the GD algorithm as a function:\n",
        "\n",
        "  \\begin{equation}\n",
        "      \\Theta_{opt} = \\text{GD}(f, \\Theta_0, \\alpha, \\rho)\n",
        "  \\end{equation}\n",
        "where $f$ is a function returning the cost and its gradient with respect to parameter vector $\\Theta$, $\\Theta_0$ is the initial value, and $\\alpha$\n",
        "is the learning rate. You can assume that $\\alpha$. remains constant during the optimization. $\\rho$ is stop condition. \\\\\n",
        "Then, use the GD algorithm to find the optimum of the [Rosenbrock function](https://en.wikipedia.org/wiki/Rosenbrock_function) (Consider $a=1, b=100$).\n",
        " \\\\\n",
        "Also, plot the values found by GD at subsequent iterations.\n",
        "\n",
        "## 2. Newton's Method\n",
        "Newton's method is an iterative optimization algorithm used to find the minimum of a function.\n",
        "The basic update step in Newton's method is given by:\n",
        "\n",
        "\\begin{equation}\n",
        "\\Theta = \\Theta - H^{-1} \\cdot \\nabla f(\\Theta)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "Where  $ H $ is the Hessian matrix of the function at $ \\Theta $, and $ H^{-1} $ is the inverse of the Hessian matrix, used to adjust the step size and direction more accurately than just using the gradient alone (as done in gradient descent).\n",
        "\n",
        "#### Line Search\n",
        "Sometimes, Newton's method may take too large of a step, which can lead to divergence. To prevent this, a simple **line search** is used. This reduces the step size $ \\alpha $ if the function value doesn't improve after the step.\n",
        "\n",
        "Steps:\n",
        "1. Compute the gradient and Hessian matrix at the current point.\n",
        "2. Calculate the step direction by multiplying the inverse of the Hessian with the gradient.\n",
        "3. Update the point by subtracting the step from the current point.\n",
        "4. If the function value doesn't improve, reduce the step size $ \\alpha $.\n",
        "5. Repeat until the gradient becomes sufficiently small (close to zero), indicating convergence.\n",
        "\n",
        "\n",
        "\n",
        "**Task2:** Implement Newton's method and compare it with the gradient descent. You will also need to implement a line search alogithm, e.g. (https://en.wikipedia.org/wiki/Backtracking_line_search) and make sure that the Newton's direction is indeed one along which the function is minimized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DIsMJPFs-kLd"
      },
      "outputs": [],
      "source": [
        "def rosenbrock(x):\n",
        "    \"\"\"Returns the value and gradient of Rosenbrock's function at x: 2d vector\"\"\"\n",
        "    a = 1\n",
        "    b = 100\n",
        "    x0, x1 = x[0], x[1]\n",
        "\n",
        "    # Value of the Rosenbrock function\n",
        "    val = (a - x0)**2 + b * (x1 - x0**2)**2\n",
        "\n",
        "    # Gradients\n",
        "    dv_dx0 = -2 * (a - x0) - 4 * b * x0 * (x1 - x0**2)\n",
        "    dv_dx1 = 2 * b * (x1 - x0**2)\n",
        "\n",
        "    grad = np.array([dv_dx0, dv_dx1])\n",
        "    return val, grad\n",
        "\n",
        "def rosenbrock_hessian(x):\n",
        "    \"\"\"Returns the value, gradient and hessian of Rosenbrock's function at x: 2d vector\"\"\"\n",
        "    val, grad = rosenbrock(x)\n",
        "    a = 1\n",
        "    b = 100\n",
        "    x0, x1 = x[0], x[1]\n",
        "\n",
        "    # Hessian matrix components\n",
        "    d2v_dx0x0 = 2 - 4 * b * x1 + 12 * b * x0**2\n",
        "    d2v_dx0x1 = -4 * b * x0\n",
        "    d2v_dx1x0 = -4 * b * x0\n",
        "    d2v_dx1x1 = 2 * b\n",
        "\n",
        "    # Hessian matrix\n",
        "    hessian = np.array([[d2v_dx0x0, d2v_dx0x1],\n",
        "                        [d2v_dx1x0, d2v_dx1x1]])\n",
        "\n",
        "    return val, grad, hessian\n",
        "\n",
        "\n",
        "def GD(f, theta0, alpha, stop_tolerance=1e-10, max_steps=1000000):\n",
        "    \"\"\"Runs gradient descent algorithm on f.\"\"\"\n",
        "\n",
        "    history = []\n",
        "    theta = theta0\n",
        "    step = 0\n",
        "\n",
        "    while step < max_steps:\n",
        "        # Calculate the function value and gradient at the current theta\n",
        "        val, grad = f(theta)\n",
        "\n",
        "        # Store the current theta, value, and gradient in history\n",
        "        history.append((theta.copy(), (val, grad)))\n",
        "\n",
        "        # Update theta by moving in the opposite direction of the gradient\n",
        "        theta = theta - alpha * grad\n",
        "\n",
        "        # Check if the improvement is below the tolerance level\n",
        "        if np.linalg.norm(grad) < stop_tolerance:\n",
        "            break\n",
        "\n",
        "        step += 1\n",
        "\n",
        "    return theta, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yyb5unZNaSFq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "ecc194f7-9f88-4d67-9bf9-581901db0439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found optimum at [1. 1.] in 54320 steps (true minimum is at [1,1])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Find the optimum of rosenbrock function\n",
        "\n",
        "# Initial point\n",
        "X0 = [0., 2.]\n",
        "\n",
        "# Run gradient descent\n",
        "Xopt, Xhist = GD(rosenbrock, X0, alpha=1e-3, stop_tolerance=1e-10, max_steps=int(1e6))\n",
        "\n",
        "# Print the result\n",
        "print(\"Found optimum at %s in %d steps (true minimum is at [1,1])\" % (Xopt, len(Xhist)))\n",
        "\n",
        "# Extract the values of the Rosenbrock function from history\n",
        "values = [step[1][0] for step in Xhist]\n",
        "\n",
        "# Plotting the function value over iterations\n",
        "plt.plot(values)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Function Value\")\n",
        "plt.title(\"Rosenbrock Function Value over Iterations\")\n",
        "plt.yscale(\"log\")  # Optional: Log scale to better see convergence\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JQ1Bf6sNMT_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa9d4c5-2871-4983-e72a-22e5e5948739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found optimum at [1. 1.] (true minimum is at [1,1])\n"
          ]
        }
      ],
      "source": [
        "def Newton(f, theta0, alpha=1, stop_tolerance=1e-10, max_steps=1000000):\n",
        "    \"\"\"Performs Newton's optimization method with a simple line search.\"\"\"\n",
        "    theta = np.array(theta0, dtype=float)\n",
        "    history = []\n",
        "    step = 0\n",
        "\n",
        "    while step < max_steps:\n",
        "        # Evaluate function value, gradient, and Hessian at current theta\n",
        "        val, grad, hessian = f(theta)\n",
        "\n",
        "        # Store the current state in history\n",
        "        history.append((theta.copy(), val, grad))\n",
        "\n",
        "        # Check for convergence by the gradient's norm\n",
        "        if np.linalg.norm(grad) < stop_tolerance:\n",
        "            break\n",
        "\n",
        "        # Compute the Newton step: delta = -Hessian_inv * grad\n",
        "        try:\n",
        "            hessian_inv = np.linalg.inv(hessian)\n",
        "            delta = -hessian_inv @ grad\n",
        "        except np.linalg.LinAlgError:\n",
        "            print(\"Hessian is singular, cannot proceed with Newton's method.\")\n",
        "            break\n",
        "\n",
        "        # Line search (adjust step size alpha if needed)\n",
        "        theta_next = theta + alpha * delta\n",
        "        theta = theta_next\n",
        "\n",
        "        step += 1\n",
        "\n",
        "    # Final entry in history\n",
        "    history.append((theta, val, grad))\n",
        "    return theta, history\n",
        "\n",
        "# Test Newton's method on the Rosenbrock function\n",
        "X0 = [0., 2.]  # Initial guess\n",
        "Xopt, Xhist = Newton(rosenbrock_hessian, X0)\n",
        "\n",
        "print(\"Found optimum at %s (true minimum is at [1,1])\" % Xopt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNXtvq8u-JSo"
      },
      "source": [
        "# Part two: MLP for MNIST Classification\n",
        "In this part, we are going to use `PyTorch`. If you want to become more familiar with it, check this resource: https://www.learnpytorch.io/\n",
        "\n",
        "#### In this homework, you need to\n",
        "- implement SGD optimizer (`./optimizer.py`)\n",
        "- implement forward and backward for FCLayer (`layers.py`)\n",
        "- implement forward and backward for SigmoidLayer (`layers.py`)\n",
        "- implement forward and backward for ReLULayer (`layers.py`)\n",
        "- implement forward and backward for DropoutLayer (`layers.py`)\n",
        "- implement train and test process (`solver.py`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zWtm2k5Ir-XQ"
      },
      "outputs": [],
      "source": [
        "from layers import FCLayer, SigmoidLayer, ReLULayer\n",
        "from solver import train, test\n",
        "from optimizer import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NRwL2rM0O92Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa4f0c0c-c4ea-4a3c-e100-5e8fad49a898"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bCXcnjSYaR-R"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "\n",
        "# Converts PIL image to tensor and scales to [0, 1] and flatten it\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1)),\n",
        "])\n",
        "\n",
        "# Load MNIST dataset with the defined transform\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# One-hot encoding for labels\n",
        "def decode_label(label, num_classes=10):\n",
        "    return torch.nn.functional.one_hot(torch.tensor(label), num_classes=num_classes).float()\n",
        "\n",
        "# Preprocess labels and combine with transformed images\n",
        "y_train = [decode_label(label) for _, label in train_dataset]\n",
        "y_test = [decode_label(label) for _, label in test_dataset]\n",
        "\n",
        "# Convert the data into tensor datasets for training and testing\n",
        "train_dataset = TensorDataset(torch.stack([img for img, _ in train_dataset]), torch.stack(y_train))\n",
        "test_dataset = TensorDataset(torch.stack([img for img, _ in test_dataset]), torch.stack(y_test))\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NkRty2cM-kIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97eebade-e70f-4918-f96a-70105bed539b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [0] Average training loss: 0.0771, Average training accuracy: 0.4956\n",
            "\n",
            "Epoch [1] Average training loss: 0.0556, Average training accuracy: 0.7378\n",
            "\n",
            "Epoch [2] Average training loss: 0.0506, Average training accuracy: 0.7835\n",
            "\n",
            "Epoch [3] Average training loss: 0.0482, Average training accuracy: 0.8046\n",
            "\n",
            "Epoch [4] Average training loss: 0.0466, Average training accuracy: 0.8173\n",
            "\n",
            "Epoch [5] Average training loss: 0.0456, Average training accuracy: 0.8254\n",
            "\n",
            "Epoch [6] Average training loss: 0.0448, Average training accuracy: 0.8307\n",
            "\n",
            "Epoch [7] Average training loss: 0.0442, Average training accuracy: 0.8344\n",
            "\n",
            "Epoch [8] Average training loss: 0.0437, Average training accuracy: 0.8384\n",
            "\n",
            "Epoch [9] Average training loss: 0.0432, Average training accuracy: 0.8408\n",
            "\n",
            "Epoch [10] Average training loss: 0.0429, Average training accuracy: 0.8430\n",
            "\n",
            "Epoch [11] Average training loss: 0.0426, Average training accuracy: 0.8455\n",
            "\n",
            "Epoch [12] Average training loss: 0.0423, Average training accuracy: 0.8465\n",
            "\n",
            "Epoch [13] Average training loss: 0.0420, Average training accuracy: 0.8474\n",
            "\n",
            "Epoch [14] Average training loss: 0.0418, Average training accuracy: 0.8489\n",
            "\n",
            "Epoch [15] Average training loss: 0.0415, Average training accuracy: 0.8504\n",
            "\n",
            "Epoch [16] Average training loss: 0.0413, Average training accuracy: 0.8517\n",
            "\n",
            "Epoch [17] Average training loss: 0.0411, Average training accuracy: 0.8514\n",
            "\n",
            "Epoch [18] Average training loss: 0.0409, Average training accuracy: 0.8529\n",
            "\n",
            "Epoch [19] Average training loss: 0.0407, Average training accuracy: 0.8533\n"
          ]
        }
      ],
      "source": [
        "num_epoch = 20\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Build MLP with FCLayer and SigmoidLayer you've implemented in layers.py\n",
        "sigmoidMLP = nn.Sequential(\n",
        "    FCLayer(784, 128),\n",
        "    SigmoidLayer(),\n",
        "    FCLayer(128, 10)\n",
        ")\n",
        "\n",
        "# Initialize optimizer you've implemented in optimizer.py\n",
        "sgd = SGD(params=sigmoidMLP.parameters(), learning_rate=0.01)\n",
        "\n",
        "# Train the model using train function you've implemented in solver.py\n",
        "sigmoidMLP = train(sigmoidMLP, criterion, sgd, train_dataloader, num_epoch, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F0otZUFrr7WW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56bfe70-4b32-4f94-9a10-805e6fdc68da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The test accuracy is 0.8627.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test your model using test function you've implemented in solver.py\n",
        "test(sigmoidMLP, test_dataloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "n-2V-B_er7T2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f661392c-be83-46ae-8ecb-6a7175b5afbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [0] Average training loss: 0.0712, Average training accuracy: 0.6373\n",
            "\n",
            "Epoch [1] Average training loss: 0.0467, Average training accuracy: 0.8231\n",
            "\n",
            "Epoch [2] Average training loss: 0.0399, Average training accuracy: 0.8589\n",
            "\n",
            "Epoch [3] Average training loss: 0.0357, Average training accuracy: 0.8765\n",
            "\n",
            "Epoch [4] Average training loss: 0.0327, Average training accuracy: 0.8875\n",
            "\n",
            "Epoch [5] Average training loss: 0.0305, Average training accuracy: 0.8953\n",
            "\n",
            "Epoch [6] Average training loss: 0.0288, Average training accuracy: 0.9011\n",
            "\n",
            "Epoch [7] Average training loss: 0.0274, Average training accuracy: 0.9060\n",
            "\n",
            "Epoch [8] Average training loss: 0.0262, Average training accuracy: 0.9103\n",
            "\n",
            "Epoch [9] Average training loss: 0.0253, Average training accuracy: 0.9131\n",
            "\n",
            "Epoch [10] Average training loss: 0.0244, Average training accuracy: 0.9162\n",
            "\n",
            "Epoch [11] Average training loss: 0.0237, Average training accuracy: 0.9185\n",
            "\n",
            "Epoch [12] Average training loss: 0.0231, Average training accuracy: 0.9205\n",
            "\n",
            "Epoch [13] Average training loss: 0.0225, Average training accuracy: 0.9227\n",
            "\n",
            "Epoch [14] Average training loss: 0.0220, Average training accuracy: 0.9248\n",
            "\n",
            "Epoch [15] Average training loss: 0.0215, Average training accuracy: 0.9264\n",
            "\n",
            "Epoch [16] Average training loss: 0.0211, Average training accuracy: 0.9279\n",
            "\n",
            "Epoch [17] Average training loss: 0.0207, Average training accuracy: 0.9289\n",
            "\n",
            "Epoch [18] Average training loss: 0.0204, Average training accuracy: 0.9297\n",
            "\n",
            "Epoch [19] Average training loss: 0.0200, Average training accuracy: 0.9309\n"
          ]
        }
      ],
      "source": [
        "# Build MLP with FCLayer and ReLULayer\n",
        "reluMLP = nn.Sequential(\n",
        "    FCLayer(784, 128),\n",
        "    ReLULayer(),\n",
        "    FCLayer(128, 10)\n",
        ")\n",
        "\n",
        "# Initialize optimizer\n",
        "sgd = SGD(reluMLP.parameters(), learning_rate=0.01)\n",
        "\n",
        "# Train the model\n",
        "reluMLP = train(reluMLP, criterion, sgd, train_dataloader, num_epoch, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sLjxTbq8r7RZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ae41d3-ed8e-4b29-966f-f8c8f7439005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The test accuracy is 0.9313.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "test(reluMLP, test_dataloader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krsqZLJ-qQKH"
      },
      "source": [
        "### Overfit the model\n",
        "Try to overfit the reluMLP model. You can make the model as complex as you like, use subset of the data for training or any other approach you want.\n",
        "Then add **DropoutLayer** to your model in order to reduce overfitting problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XbVFtro9qP1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deea6c71-ae5e-430f-8d5b-4b1200e0b420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [0] Average training loss: 2.3196, Average training accuracy: 0.1160\n",
            "\n",
            "Epoch [1] Average training loss: 2.2260, Average training accuracy: 0.1586\n",
            "\n",
            "Epoch [2] Average training loss: 2.1477, Average training accuracy: 0.2223\n",
            "\n",
            "Epoch [3] Average training loss: 2.0586, Average training accuracy: 0.3168\n",
            "\n",
            "Epoch [4] Average training loss: 1.9621, Average training accuracy: 0.4418\n",
            "\n",
            "Epoch [5] Average training loss: 1.8518, Average training accuracy: 0.5211\n",
            "\n",
            "Epoch [6] Average training loss: 1.7365, Average training accuracy: 0.5832\n",
            "\n",
            "Epoch [7] Average training loss: 1.6101, Average training accuracy: 0.6426\n",
            "\n",
            "Epoch [8] Average training loss: 1.4875, Average training accuracy: 0.7215\n",
            "\n",
            "Epoch [9] Average training loss: 1.3491, Average training accuracy: 0.7543\n",
            "\n",
            "Epoch [10] Average training loss: 1.2241, Average training accuracy: 0.7770\n",
            "\n",
            "Epoch [11] Average training loss: 1.1085, Average training accuracy: 0.7891\n",
            "\n",
            "Epoch [12] Average training loss: 1.0017, Average training accuracy: 0.8098\n",
            "\n",
            "Epoch [13] Average training loss: 0.9173, Average training accuracy: 0.8285\n",
            "\n",
            "Epoch [14] Average training loss: 0.8350, Average training accuracy: 0.8430\n",
            "\n",
            "Epoch [15] Average training loss: 0.7603, Average training accuracy: 0.8570\n",
            "\n",
            "Epoch [16] Average training loss: 0.7070, Average training accuracy: 0.8582\n",
            "\n",
            "Epoch [17] Average training loss: 0.6533, Average training accuracy: 0.8703\n",
            "\n",
            "Epoch [18] Average training loss: 0.6094, Average training accuracy: 0.8656\n",
            "\n",
            "Epoch [19] Average training loss: 0.5663, Average training accuracy: 0.8695\n",
            "The test accuracy is 0.7630.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define a more complex MLP model to encourage overfitting\n",
        "complex_reluMLP = nn.Sequential(\n",
        "    FCLayer(784, 256),\n",
        "    ReLULayer(),\n",
        "    FCLayer(256, 128),\n",
        "    ReLULayer(),\n",
        "    FCLayer(128, 64),\n",
        "    ReLULayer(),\n",
        "    FCLayer(64, 10)\n",
        ")\n",
        "\n",
        "# Initialize optimizer\n",
        "sgd = SGD(complex_reluMLP.parameters(), learning_rate=0.01)\n",
        "\n",
        "# Use a smaller subset of the training data to encourage overfitting\n",
        "subset_size = 500  # Use only 500 samples for training to induce overfitting\n",
        "subset_train_dataloader = DataLoader(\n",
        "    torch.utils.data.Subset(train_dataset, range(subset_size)),\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Train the complex model on the subset\n",
        "num_epoch = 20  # Increase epochs to further encourage memorization\n",
        "criterion = nn.CrossEntropyLoss()  # Define a loss function\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "complex_reluMLP = train(complex_reluMLP, criterion, sgd, subset_train_dataloader, num_epoch, device=device)\n",
        "\n",
        "# Test the model to observe overfitting\n",
        "test(complex_reluMLP, test_dataloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BeCfvh6Jr7Om",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2cc3dbb-17ac-4d8b-f2e9-b2b714c3f7f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [0] Average training loss: 1.4620, Average training accuracy: 0.4889\n",
            "\n",
            "Epoch [1] Average training loss: 0.7382, Average training accuracy: 0.7711\n",
            "\n",
            "Epoch [2] Average training loss: 0.5631, Average training accuracy: 0.8368\n",
            "\n",
            "Epoch [3] Average training loss: 0.4718, Average training accuracy: 0.8667\n",
            "\n",
            "Epoch [4] Average training loss: 0.4164, Average training accuracy: 0.8863\n",
            "\n",
            "Epoch [5] Average training loss: 0.3711, Average training accuracy: 0.9000\n",
            "\n",
            "Epoch [6] Average training loss: 0.3419, Average training accuracy: 0.9093\n",
            "\n",
            "Epoch [7] Average training loss: 0.3144, Average training accuracy: 0.9165\n",
            "\n",
            "Epoch [8] Average training loss: 0.2947, Average training accuracy: 0.9213\n",
            "\n",
            "Epoch [9] Average training loss: 0.2795, Average training accuracy: 0.9267\n",
            "\n",
            "Epoch [10] Average training loss: 0.2653, Average training accuracy: 0.9298\n",
            "\n",
            "Epoch [11] Average training loss: 0.2502, Average training accuracy: 0.9351\n",
            "\n",
            "Epoch [12] Average training loss: 0.2415, Average training accuracy: 0.9365\n",
            "\n",
            "Epoch [13] Average training loss: 0.2270, Average training accuracy: 0.9397\n",
            "\n",
            "Epoch [14] Average training loss: 0.2183, Average training accuracy: 0.9425\n",
            "\n",
            "Epoch [15] Average training loss: 0.2137, Average training accuracy: 0.9437\n",
            "\n",
            "Epoch [16] Average training loss: 0.2105, Average training accuracy: 0.9458\n",
            "\n",
            "Epoch [17] Average training loss: 0.1986, Average training accuracy: 0.9479\n",
            "\n",
            "Epoch [18] Average training loss: 0.1907, Average training accuracy: 0.9504\n",
            "\n",
            "Epoch [19] Average training loss: 0.1880, Average training accuracy: 0.9512\n",
            "The test accuracy is 0.9694.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from layers import DropoutLayer\n",
        "\n",
        "# Define the MLP model with Dropout layers to reduce overfitting\n",
        "dropout_reluMLP = nn.Sequential(\n",
        "    FCLayer(784, 256),\n",
        "    ReLULayer(),\n",
        "    DropoutLayer(0.5),  # 50% dropout rate\n",
        "    FCLayer(256, 128),\n",
        "    ReLULayer(),\n",
        "    DropoutLayer(0.5),  # 50% dropout rate\n",
        "    FCLayer(128, 64),\n",
        "    ReLULayer(),\n",
        "    DropoutLayer(0.5),  # 50% dropout rate\n",
        "    FCLayer(64, 10)\n",
        ")\n",
        "\n",
        "# Initialize the optimizer\n",
        "sgd = SGD(dropout_reluMLP.parameters(), learning_rate=0.01)\n",
        "\n",
        "# Train the model with Dropout\n",
        "num_epoch = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "dropout_reluMLP = train(dropout_reluMLP, criterion, sgd, train_dataloader, num_epoch, device=device)\n",
        "\n",
        "# Test the model with Dropout\n",
        "test(dropout_reluMLP, test_dataloader, device)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}